{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the original CSV file\n",
    "# Replace 'airlines_original.csv' with the path to your CSV file\n",
    "input_file = 'Revenue_Growth.csv'\n",
    "output_file = 'Revenue_Growth_ideal_format.csv'\n",
    "\n",
    "# Read the CSV file without headers because the structure is custom\n",
    "df = pd.read_csv(input_file, header=None)\n",
    "\n",
    "# Step 2: Extract Column Names and Data\n",
    "# The first row contains the labels for the columns (e.g., 'Airline', 'Status', etc.)\n",
    "column_labels = df.iloc[0, 1:].tolist()  # Skip the first column which is labels\n",
    "column_labels.insert(0, 'Attribute')     # Add 'Attribute' as the first column name\n",
    "\n",
    "# Assign column names to the DataFrame\n",
    "df.columns = column_labels\n",
    "\n",
    "# Remove the first row since it's now used as headers\n",
    "df = df.drop(0).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Transpose the DataFrame\n",
    "# Set 'Attribute' as the index to transpose correctly\n",
    "df.set_index('Attribute', inplace=True)\n",
    "\n",
    "# Transpose the DataFrame\n",
    "df_transposed = df.T.reset_index().rename(columns={'index': 'Airline'})\n",
    "\n",
    "# Step 4: Melt the DataFrame to Long Format\n",
    "# Identify columns that are dates (assuming they contain a \"'Q\" pattern)\n",
    "date_columns = [col for col in df_transposed.columns if \"'Q\" in col]\n",
    "\n",
    "# Melt the DataFrame to have 'Date', 'Value' columns\n",
    "long_df = pd.melt(df_transposed, id_vars=['Airline'], value_vars=date_columns,\n",
    "                  var_name='Date', value_name='Revenue')\n",
    "\n",
    "# Step 5: Clean the Data\n",
    "# Remove dollar signs and commas from 'Value' and convert to numeric\n",
    "long_df['Revenue'] = long_df['Revenue'].replace({'%': '', ',': ''}, regex=True)\n",
    "long_df['Revenue'] = pd.to_numeric(long_df['Revenue'], errors='coerce')\n",
    "\n",
    "# Remove any rows with missing or zero values if necessary\n",
    "long_df = long_df.dropna(subset=['Revenue'])\n",
    "long_df = long_df[long_df['Revenue'] != 0]\n",
    "\n",
    "# Optional: If you have 'Status', 'Country', etc., merge them back\n",
    "# Extract 'Status', 'Country', etc., from df_transposed\n",
    "metadata_cols = ['Airline', 'Status', 'Country', 'Region','IATA']\n",
    "metadata = df_transposed[metadata_cols].drop_duplicates()\n",
    "\n",
    "# Merge metadata back into the long DataFrame\n",
    "final_df = pd.merge(long_df, metadata, on='Airline', how='left')\n",
    "\n",
    "# Step 6: Save the Data to a New CSV File\n",
    "final_df.to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the original CSV file\n",
    "# Replace 'airlines_original.csv' with the path to your CSV file\n",
    "input_file = 'EBITDA.csv'\n",
    "output_file = 'EBITDA_ideal_format.csv'\n",
    "\n",
    "# Read the CSV file without headers because the structure is custom\n",
    "df = pd.read_csv(input_file, header=None)\n",
    "\n",
    "# Step 2: Extract Column Names and Data\n",
    "# The first row contains the labels for the columns (e.g., 'Airline', 'Status', etc.)\n",
    "column_labels = df.iloc[0, 1:].tolist()  # Skip the first column which is labels\n",
    "column_labels.insert(0, 'Attribute')     # Add 'Attribute' as the first column name\n",
    "\n",
    "# Assign column names to the DataFrame\n",
    "df.columns = column_labels\n",
    "\n",
    "# Remove the first row since it's now used as headers\n",
    "df = df.drop(0).reset_index(drop=True)\n",
    "\n",
    "# Step 3: Transpose the DataFrame\n",
    "# Set 'Attribute' as the index to transpose correctly\n",
    "df.set_index('Attribute', inplace=True)\n",
    "\n",
    "# Transpose the DataFrame\n",
    "df_transposed = df.T.reset_index().rename(columns={'index': 'Airline'})\n",
    "\n",
    "# Step 4: Melt the DataFrame to Long Format\n",
    "# Identify columns that are dates (assuming they contain a \"'Q\" pattern)\n",
    "date_columns = [col for col in df_transposed.columns if \"'Q\" in col]\n",
    "\n",
    "# Melt the DataFrame to have 'Date', 'Value' columns\n",
    "long_df = pd.melt(df_transposed, id_vars=['Airline'], value_vars=date_columns,\n",
    "                  var_name='Date', value_name='EBITDA')\n",
    "\n",
    "# Step 5: Clean the Data\n",
    "# Remove dollar signs and commas from 'Value' and convert to numeric\n",
    "long_df['EBITDA'] = long_df['EBITDA'].replace({'%': '', ',': ''}, regex=True)\n",
    "long_df['EBITDA'] = pd.to_numeric(long_df['EBITDA'], errors='coerce')\n",
    "\n",
    "# Remove any rows with missing or zero values if necessary\n",
    "long_df = long_df.dropna(subset=['EBITDA'])\n",
    "long_df = long_df[long_df['EBITDA'] != 0]\n",
    "\n",
    "# Optional: If you have 'Status', 'Country', etc., merge them back\n",
    "# Extract 'Status', 'Country', etc., from df_transposed\n",
    "metadata_cols = ['Airline', 'Status', 'Country', 'Region','IATA']\n",
    "metadata = df_transposed[metadata_cols].drop_duplicates()\n",
    "\n",
    "# Merge metadata back into the long DataFrame\n",
    "final_df = pd.merge(long_df, metadata, on='Airline', how='left')\n",
    "\n",
    "# Step 6: Save the Data to a New CSV File\n",
    "final_df.to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m final_merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(merged_df1, df3, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAirline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Save the final merged DataFrame to a new CSV\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m final_merged_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBubble.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3900\u001b[0m )\n\u001b[0;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m   3903\u001b[0m     path_or_buf,\n\u001b[1;32m   3904\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   3905\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   3906\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   3907\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   3908\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   3909\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   3910\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   3911\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3912\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   3913\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3914\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[1;32m   3915\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   3916\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[1;32m   3917\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[1;32m   3918\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   3919\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1151\u001b[0m )\n\u001b[0;32m-> 1152\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:271\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_body()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:309\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_chunk(start_i, end_i)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:320\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    317\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[1;32m    319\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 320\u001b[0m libwriters\u001b[38;5;241m.\u001b[39mwrite_csv_rows(\n\u001b[1;32m    321\u001b[0m     data,\n\u001b[1;32m    322\u001b[0m     ix,\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels,\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter,\n\u001b[1;32m    326\u001b[0m )\n",
      "File \u001b[0;32mwriters.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "df1 = pd.read_csv('airlines_ideal_format.csv')  # Contains 'Value' column\n",
    "df2 = pd.read_csv('Revenue_Growth_ideal_format.csv')  # Contains 'Revenue' column\n",
    "df3 = pd.read_csv('EBITDA_ideal_format.csv')  # Contains 'EBITDA' column\n",
    "\n",
    "# Merge df1 and df2 on the common columns\n",
    "merged_df1 = pd.merge(df1, df2, on=['Airline', 'Date', 'Status', 'Country', 'Region', 'IATA'])\n",
    "\n",
    "# Merge the result with df3 on the same common columns\n",
    "final_merged_df = pd.merge(merged_df1, df3, on=['Airline', 'Date', 'Status', 'Country', 'Region', 'IATA'])\n",
    "\n",
    "# Save the final merged DataFrame to a new CSV\n",
    "final_merged_df.to_csv('Bubble.csv', index=False)\n",
    "\n",
    "# Optionally, display the result for verification\n",
    "print(final_merged_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
